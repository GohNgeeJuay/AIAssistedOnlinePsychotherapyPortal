{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Script.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WlvVZh09nS9G"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoencWsBhsGx"
      },
      "source": [
        "#Import libraries\n",
        "import sys\n",
        "import cv2\n",
        "import pathlib\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import keras\n",
        "from glob import glob, iglob\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import pickle\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "import operator\n",
        "from decimal import Decimal\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J3DvMcMEoNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f946d63-7def-4738-c369-b7dfedc4c321"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlvVZh09nS9G"
      },
      "source": [
        "# Global Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asCHttyhnVEN"
      },
      "source": [
        "directory = \"\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8NUQRjEnYQW"
      },
      "source": [
        "# Extracting Faces & Resizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNmttWJInfcI"
      },
      "source": [
        "def extract_face(img_list, min_size = (200,200)):\n",
        "  idx = 0 \n",
        "  while idx < len(img_list):\n",
        "    img = img_list[idx]\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor = 1.05, minNeighbors = 5, minSize= min_size ) #, minSize = (200,200)) \n",
        "  \n",
        "    for (x, y, w, h) in faces:\n",
        "      #if x == 0 or y == 0 or w == 0 or h == 0:\n",
        "      #  print(\"None\")\n",
        "      faces = img[y:y + h, x:x + w]\n",
        "      faces = cv2.resize(faces, (224,224),interpolation = cv2.INTER_AREA)\n",
        "\n",
        "    if len(faces) != 0:\n",
        "      img_list[idx] = faces\n",
        "      idx += 1\n",
        "    else:\n",
        "      img_list.pop(idx)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RviqXjDwmM1o"
      },
      "source": [
        "# Splitting video into images, extracting faces & resizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCmsQB3RjlOx"
      },
      "source": [
        "def extract_images(pathIn): #, pathOut):\n",
        "    to_return = []\n",
        "    count = 0\n",
        "    vidcap = cv2.VideoCapture(pathIn)\n",
        "    success,image = vidcap.read()    #Grabs, decodes and returns the next video frame.\n",
        "    success = True\n",
        "    while success:\n",
        "        vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*500))    # added this line. set() = set a property in video capture #0.167 for 6 frames per sec -> 6 img/3 sec\n",
        "        #CAP_PROP_POS_MSEC = Current position of the video file in milliseconds.\n",
        "        success,image = vidcap.read()\n",
        "        if success == True:    #If have read in a new frame\n",
        "          #cv2.imwrite(os.path.join(pathOut + \"/frame_%d_.jpg\" % count), image)     # save frame as JPEG file\n",
        "          to_return.append(image)\n",
        "        count = count + 1\n",
        "\n",
        "    return to_return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QX9i7GfmiBB"
      },
      "source": [
        "def slice_video(video_name):\n",
        "  #directory must have been set, will be a global variable\n",
        "  sourceVideoDirectory = os.path.join(directory, video_name)\n",
        "  #targetVideoDirectory = os.path.join(directory + \"sliced\", video_name)\n",
        "\n",
        "  #Create the target video directory if does not exist. Reference: https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python\n",
        "  # pathlib.Path(targetVideoDirectory).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  #Split the video into frames. \n",
        "  return extract_images(sourceVideoDirectory) #, targetVideoDirectory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqt0Ik8lMujj"
      },
      "source": [
        "# Data duplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09hZCBOfNCMf"
      },
      "source": [
        "def duplicate(img_list):\n",
        "  n = len(img_list)\n",
        "  if n % 6 != 0:\n",
        "    duplicate_num = 6 - (n%6)\n",
        "\n",
        "    for i in range(duplicate_num):\n",
        "      img_list.append(img_list[-1])\n",
        "\n",
        "  return len(img_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d5vUDwZRt2v"
      },
      "source": [
        "# Creating list of images in np.arr form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5QYoNV_RvSP"
      },
      "source": [
        "def transform_img(img_list):\n",
        "  #img_list.sort(key = lambda x : int(x[1]))\n",
        "  img_list = np.asarray(img_list)\n",
        "  img_list = [np.expand_dims(img,0) for img in img_list]\n",
        "\n",
        "  return img_list #return a list of tuple (np.arr of image, image code)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgjMruTzuOYY"
      },
      "source": [
        "# Predicted label and time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HbmWzCWuSQh"
      },
      "source": [
        "def get_label_time(arr, threshold = 0.30):\n",
        "  to_return = []\n",
        "  time_str = \"\" \n",
        "\n",
        "  for i in range(len(arr)):\n",
        "    prob = arr[i][0]\n",
        "    idx = arr[i][1][0]\n",
        "\n",
        "    if prob > threshold:\n",
        "      hour = i*3 // 3600\n",
        "      minute = i*3 // 60\n",
        "      second = i*3 % 60\n",
        "\n",
        "      if hour == 0 and minute == 0 and second == 0:\n",
        "        pass\n",
        "      else:\n",
        "        if hour != 0:\n",
        "          time_str += str(hour)\n",
        "        \n",
        "        # add minute\n",
        "        if hour != 0 and len(str(minute)) == 1:\n",
        "          time_str += \":0\" + str(minute)\n",
        "        \n",
        "        else: #hour == 0 and len(minute)\n",
        "          time_str += str(minute)\n",
        "\n",
        "        # add second\n",
        "        if len(str(second)) == 1:\n",
        "          time_str += \":0\" + str(second)\n",
        "\n",
        "        else:\n",
        "          time_str += \":\" + str(second)\n",
        "\n",
        "        to_return.append((label_code[idx], time_str))\n",
        "      time_str = \"\" \n",
        "\n",
        "  return to_return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHyHzAgrXT-6"
      },
      "source": [
        "# Main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caBwcSc7Xllx"
      },
      "source": [
        "def main(file_name):\n",
        "  # process file\n",
        "  # 1 - Slice video\n",
        "  extracted_img = slice_video(file_name)\n",
        "\n",
        "  # 2 - Extract face only & resize image\n",
        "  extract_face(extracted_img)\n",
        "\n",
        "  # 3 - Do data duplication & tansfrom image\n",
        "  duplicate(extracted_img)\n",
        "  img_list = transform_img(extracted_img)\n",
        "\n",
        "  # 5 - Do prediction\n",
        "  predicted_list = []\n",
        "  for i in range(0, len(img_list),6):\n",
        "    input = img_list[i:i+6]\n",
        "    yhat = trainedModel.predict(input) #Use verbose to get progress bar\n",
        "    predicted_list.append((yhat.max(), np.argmax(yhat, axis=1)))\n",
        "\n",
        "  return get_label_time(predicted_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCNd0nJb6l8H"
      },
      "source": [
        "#trainedModel = keras.models.load_model(\"/content/drive/Shareddrives/Final Year Project/CS 2/Deep Learning Models/finetunecheckpoint6epochs0.40acc.hdf5\")\n",
        "trainedModel = keras.models.load_model(\"/content/drive/Shareddrives/Final Year Project/CS 2/Deep Learning Models/savedManually34epochs0.5acc.h5\")\n",
        "#trainedModel = keras.models.load_model(\"/content/drive/Shareddrives/Final Year Project/CS 2/Deep Learning Models/0.6acc.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MokhGDUEPPq"
      },
      "source": [
        "label_code = {0: 'anger', 1: 'disgust', 2 : 'fear', 3 : 'happy', 4 : 'sad', 5 : 'surprise'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiuuuXPdA_PE"
      },
      "source": [
        "directory = \"/content/drive/Shareddrives/Final Year Project/CS 2/Quality Assurance/Test videos FER finalized/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1RE7MsnAmSZ",
        "outputId": "6d53f2a7-843c-43ae-bf18-639e6a8dc356"
      },
      "source": [
        "main('test video.mp4') #savedManually34epochs0.5acc.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('happy', '0:03'),\n",
              " ('happy', '0:09'),\n",
              " ('happy', '0:12'),\n",
              " ('happy', '0:15'),\n",
              " ('happy', '0:18'),\n",
              " ('surprise', '0:21'),\n",
              " ('sad', '0:24'),\n",
              " ('sad', '0:27'),\n",
              " ('happy', '0:30'),\n",
              " ('happy', '0:33'),\n",
              " ('happy', '0:36'),\n",
              " ('happy', '0:39')]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJA_W3nw4Bjv"
      },
      "source": [
        "# Manual Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4M9G38c5RNF"
      },
      "source": [
        "directory = \"/content/drive/Shareddrives/Final Year Project/CS 2/Quality Assurance/Test videos FER finalized/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8etcQ-XD4Ym4"
      },
      "source": [
        "file_name = ['1meterhappy.mp4', 'halfmetersad.mp4', 'halfmeterhappy.mp4', 'halfmeternoisybackgroundhappy.mp4', 'halfmeternoisybackgrounddisgust.mp4']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIM_hF3uCQBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb249160-3c1b-4058-d62c-45248a0f44b5"
      },
      "source": [
        "extracted_img = slice_video('test video.mp4') # slice_video('test video.mp4')\n",
        "extract_face(extracted_img)\n",
        "duplicate(extracted_img)\n",
        "img_list = transform_img(extracted_img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKibiGYDgHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3351a03b-ac4f-4302-a3d3-7ca87fc535c9"
      },
      "source": [
        "predicted_list = [] \n",
        "for i in range(0, len(img_list),6):\n",
        "  input = img_list[i:i+6]\n",
        "  yhat = trainedModel.predict(input) # , verbose = 1) #Use verbose to get progress bar\n",
        "  predicted_list.append((yhat.max(), np.argmax(yhat, axis=1)))\n",
        "  print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00814986 0.41708964 0.29112673 0.08965836 0.13928644 0.05468889]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798016 0.29108635 0.08950234 0.13872658 0.05457048]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNjTX6AwBT7P",
        "outputId": "b21c1302-38f3-4c4f-edf5-5f7570c387a2"
      },
      "source": [
        "get_label_time(predicted_list, 0.30) #0.6acc.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('disgust', '0:03'),\n",
              " ('disgust', '0:06'),\n",
              " ('disgust', '0:09'),\n",
              " ('disgust', '0:12'),\n",
              " ('disgust', '0:15'),\n",
              " ('disgust', '0:18'),\n",
              " ('disgust', '0:21'),\n",
              " ('disgust', '0:24'),\n",
              " ('disgust', '0:27'),\n",
              " ('disgust', '0:30'),\n",
              " ('disgust', '0:33'),\n",
              " ('disgust', '0:36'),\n",
              " ('disgust', '0:39')]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk0D27ab74pl",
        "outputId": "aeb077a9-007d-4705-a7cd-6c321a9b907f"
      },
      "source": [
        "for video_name in file_name:\n",
        "  print(video_name)\n",
        "  extracted_img = slice_video(video_name)\n",
        "  extract_face(extracted_img)\n",
        "  duplicate(extracted_img)\n",
        "  img_list = transform_img(extracted_img)\n",
        "\n",
        "  predicted_list = []\n",
        "  for i in range(0, len(img_list),6):\n",
        "    input = img_list[i:i+6]\n",
        "    yhat = trainedModel.predict(input) # , verbose = 1) #Use verbose to get progress bar\n",
        "    predicted_list.append((yhat.max(), np.argmax(yhat, axis=1)))\n",
        "    print(yhat,)\n",
        "\n",
        "  print(get_label_time(predicted_list),\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1meterhappy.mp4\n",
            "[[0.00894982 0.3735591  0.2917214  0.09683622 0.16858701 0.06034643]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950235 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813405 0.4179783  0.29108658 0.08950264 0.13872771 0.05457076]]\n",
            "[[0.00813407 0.41797802 0.2910864  0.08950273 0.13872795 0.05457076]]\n",
            "[[0.00813488 0.4178966  0.2910919  0.08951686 0.13877797 0.05458185]]\n",
            "[[0.00813415 0.41795948 0.29108867 0.08950562 0.13873863 0.05457347]]\n",
            "[[0.00813404 0.41798016 0.29108635 0.08950234 0.13872659 0.05457048]]\n",
            "[[0.00813405 0.41797954 0.29108644 0.08950242 0.13872692 0.05457057]]\n",
            "[[0.00813405 0.41797975 0.2910864  0.08950242 0.13872686 0.05457054]]\n",
            "[('disgust', '0:03'), ('disgust', '0:06'), ('disgust', '0:09'), ('disgust', '0:12'), ('disgust', '0:15'), ('disgust', '0:18'), ('disgust', '0:21'), ('disgust', '0:24'), ('disgust', '0:27')] \n",
            "\n",
            "halfmetersad.mp4\n",
            "[[0.00837561 0.3332132  0.29043067 0.10336053 0.19878654 0.06583356]]\n",
            "[[0.00820949 0.40328422 0.291858   0.09207655 0.14797065 0.05660108]]\n",
            "[[0.00813439 0.4179604  0.2910873  0.08950581 0.13873899 0.05457312]]\n",
            "[[0.00813405 0.41798013 0.2910864  0.08950236 0.13872667 0.0545705 ]]\n",
            "[[0.0081361  0.41768783 0.29111376 0.08955039 0.13890027 0.05461167]]\n",
            "[[0.00815708 0.2535634  0.28836015 0.10860112 0.26297525 0.07834301]]\n",
            "[[0.0092267  0.21275866 0.2662736  0.11537556 0.31950542 0.07686003]]\n",
            "[('disgust', '0:03'), ('disgust', '0:06'), ('disgust', '0:09'), ('disgust', '0:12'), ('fear', '0:15'), ('sad', '0:18')] \n",
            "\n",
            "halfmeterhappy.mp4\n",
            "[[0.00820883 0.41388953 0.2912588  0.09021611 0.14131036 0.05511636]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813469 0.417942   0.29108816 0.08950905 0.13875055 0.05457558]]\n",
            "[[0.00813411 0.4179736  0.29108664 0.08950354 0.13873075 0.05457136]]\n",
            "[[0.00813404 0.41798016 0.29108638 0.08950233 0.13872658 0.05457048]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[('disgust', '0:03'), ('disgust', '0:06'), ('disgust', '0:09'), ('disgust', '0:12'), ('disgust', '0:15'), ('disgust', '0:18')] \n",
            "\n",
            "halfmeternoisybackgroundhappy.mp4\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[('disgust', '0:03'), ('disgust', '0:06')] \n",
            "\n",
            "halfmeternoisybackgrounddisgust.mp4\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[[0.00813404 0.41798022 0.29108638 0.08950233 0.13872659 0.05457047]]\n",
            "[('disgust', '0:03'), ('disgust', '0:06'), ('disgust', '0:09'), ('disgust', '0:12')] \n",
            "\n"
          ]
        }
      ]
    }
  ]
}